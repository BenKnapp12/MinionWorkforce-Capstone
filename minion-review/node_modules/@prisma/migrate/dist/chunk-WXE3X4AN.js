"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var chunk_WXE3X4AN_exports = {};
__export(chunk_WXE3X4AN_exports, {
  DbPush: () => DbPush
});
module.exports = __toCommonJS(chunk_WXE3X4AN_exports);
var import_chunk_EXY2VDLY = require("./chunk-EXY2VDLY.js");
var import_chunk_3WC4XD74 = require("./chunk-3WC4XD74.js");
var import_chunk_2FXU5NZQ = require("./chunk-2FXU5NZQ.js");
var import_chunk_74LUB4XX = require("./chunk-74LUB4XX.js");
var import_chunk_F3JIZWIS = require("./chunk-F3JIZWIS.js");
var import_chunk_SKRR5WT4 = require("./chunk-SKRR5WT4.js");
var import_internals = require("@prisma/internals");
var import_prompts = __toESM(require("prompts"));
var DbPush = class _DbPush {
  static new() {
    return new _DbPush();
  }
  static help = (0, import_internals.format)(`
${process.platform === "win32" ? "" : "\u{1F64C}  "}Push the state from your Prisma schema to your database

${(0, import_chunk_SKRR5WT4.bold)("Usage")}

  ${(0, import_chunk_SKRR5WT4.dim)("$")} prisma db push [options]

${(0, import_chunk_SKRR5WT4.bold)("Options")}

           -h, --help   Display this help message
             --config   Custom path to your Prisma config file
             --schema   Custom path to your Prisma schema
   --accept-data-loss   Ignore data loss warnings
        --force-reset   Force a reset of the database before push
      --skip-generate   Skip triggering generators (e.g. Prisma Client)

${(0, import_chunk_SKRR5WT4.bold)("Examples")}

  Push the Prisma schema state to the database
  ${(0, import_chunk_SKRR5WT4.dim)("$")} prisma db push

  Specify a schema
  ${(0, import_chunk_SKRR5WT4.dim)("$")} prisma db push --schema=./schema.prisma

  Ignore data loss warnings
  ${(0, import_chunk_SKRR5WT4.dim)("$")} prisma db push --accept-data-loss
`);
  async parse(argv, config) {
    const args = (0, import_internals.arg)(
      argv,
      {
        "--help": Boolean,
        "-h": "--help",
        "--accept-data-loss": Boolean,
        "--force-reset": Boolean,
        "--skip-generate": Boolean,
        "--schema": String,
        "--config": String,
        "--telemetry-information": String
      },
      false
    );
    if ((0, import_internals.isError)(args)) {
      return this.help(args.message);
    }
    if (args["--help"]) {
      return this.help();
    }
    await (0, import_internals.loadEnvFile)({ schemaPath: args["--schema"], printMessage: true, config });
    const schemaContext = await (0, import_internals.loadSchemaContext)({
      schemaPathFromArg: args["--schema"],
      schemaPathFromConfig: config.schema
    });
    const { migrationsDirPath } = (0, import_internals.inferDirectoryConfig)(schemaContext, config);
    (0, import_internals.checkUnsupportedDataProxy)({ cmd: "db push", schemaContext });
    const datasourceInfo = (0, import_chunk_74LUB4XX.parseDatasourceInfo)(schemaContext.primaryDatasource);
    const adapter = await config.adapter?.();
    (0, import_chunk_2FXU5NZQ.printDatasource)({ datasourceInfo, adapter });
    const schemaFilter = {
      externalTables: config.tables?.external ?? [],
      externalEnums: config.enums?.external ?? []
    };
    const migrate = await import_chunk_F3JIZWIS.Migrate.setup({ adapter, migrationsDirPath, schemaContext, schemaFilter });
    if (!adapter) {
      try {
        const wasDbCreated = await (0, import_chunk_74LUB4XX.ensureDatabaseExists)(schemaContext.primaryDatasource);
        if (wasDbCreated) {
          process.stdout.write("\n" + wasDbCreated + "\n");
        }
      } catch (e) {
        process.stdout.write("\n");
        throw e;
      }
    }
    let wasDatabaseReset = false;
    if (args["--force-reset"]) {
      process.stdout.write("\n");
      (0, import_chunk_EXY2VDLY.aiAgentConfirmationCheckpoint)();
      try {
        await migrate.reset();
      } catch (e) {
        await migrate.stop();
        throw e;
      }
      let successfulResetMsg = `The ${datasourceInfo.prettyProvider} database`;
      if (datasourceInfo.dbName) {
        successfulResetMsg += ` "${datasourceInfo.dbName}"`;
      }
      const schemasLength = datasourceInfo.schemas?.length || 0;
      if (datasourceInfo.schemas && schemasLength > 0) {
        successfulResetMsg += ` schema${schemasLength > 1 ? "s" : ""} "${datasourceInfo.schemas.join(", ")}"`;
      } else if (datasourceInfo.schema) {
        successfulResetMsg += ` schema "${datasourceInfo.schema}"`;
      }
      if (datasourceInfo.dbLocation) {
        successfulResetMsg += ` at "${datasourceInfo.dbLocation}"`;
      }
      successfulResetMsg += ` ${schemasLength > 1 ? "were" : "was"} successfully reset.
`;
      process.stdout.write(successfulResetMsg);
      wasDatabaseReset = true;
    }
    const before = Math.round(performance.now());
    let migration;
    try {
      migration = await migrate.push({
        force: args["--accept-data-loss"]
      });
    } catch (e) {
      await migrate.stop();
      throw e;
    }
    if (migration.unexecutable && migration.unexecutable.length > 0) {
      const messages = [];
      messages.push(`${(0, import_chunk_SKRR5WT4.bold)((0, import_chunk_SKRR5WT4.red)("\n\u26A0\uFE0F We found changes that cannot be executed:\n"))}`);
      for (const item of migration.unexecutable) {
        messages.push(`  \u2022 ${item}`);
      }
      process.stdout.write("\n");
      await migrate.stop();
      throw new Error(`${messages.join("\n")}

You may use the --force-reset flag to drop the database before push like ${(0, import_chunk_SKRR5WT4.bold)(
        (0, import_chunk_SKRR5WT4.green)((0, import_internals.getCommandWithExecutor)("prisma db push --force-reset"))
      )}
${(0, import_chunk_SKRR5WT4.bold)((0, import_chunk_SKRR5WT4.red)("All data will be lost."))}
      `);
    }
    if (migration.warnings && migration.warnings.length > 0) {
      process.stdout.write((0, import_chunk_SKRR5WT4.bold)((0, import_chunk_SKRR5WT4.yellow)(`
\u26A0\uFE0F  There might be data loss when applying the changes:

`)));
      for (const warning of migration.warnings) {
        process.stdout.write(`  \u2022 ${warning}

`);
      }
      process.stdout.write("\n");
      if (!args["--accept-data-loss"]) {
        if (!(0, import_internals.canPrompt)()) {
          await migrate.stop();
          throw new import_chunk_3WC4XD74.DbPushIgnoreWarningsWithFlagError();
        }
        process.stdout.write("\n");
        const confirmation = await (0, import_prompts.default)({
          type: "confirm",
          name: "value",
          message: `Do you want to ignore the warning(s)?`
        });
        if (!confirmation.value) {
          process.stdout.write("Push cancelled.\n");
          await migrate.stop();
          process.exit(130);
        }
        try {
          await migrate.push({
            force: true
          });
        } catch (e) {
          await migrate.stop();
          throw e;
        }
      }
    }
    await migrate.stop();
    if (!wasDatabaseReset && migration.warnings.length === 0 && migration.executedSteps === 0) {
      process.stdout.write(`
The database is already in sync with the Prisma schema.
`);
    } else {
      const migrationTimeMessage = `Done in ${(0, import_internals.formatms)(Math.round(performance.now()) - before)}`;
      const rocketEmoji = process.platform === "win32" ? "" : "\u{1F680}  ";
      const migrationSuccessStdMessage = "Your database is now in sync with your Prisma schema.";
      const migrationSuccessMongoMessage = "Your database indexes are now in sync with your Prisma schema.";
      const provider = adapter?.provider ?? schemaContext.primaryDatasource?.activeProvider;
      process.stdout.write(
        `
${rocketEmoji}${provider === "mongodb" ? migrationSuccessMongoMessage : migrationSuccessStdMessage} ${migrationTimeMessage}
`
      );
    }
    if (!process.env.PRISMA_MIGRATE_SKIP_GENERATE && !args["--skip-generate"]) {
      await migrate.tryToRunGenerate(datasourceInfo);
    }
    return ``;
  }
  help(error) {
    if (error) {
      return new import_internals.HelpError(`
${(0, import_chunk_SKRR5WT4.bold)((0, import_chunk_SKRR5WT4.red)(`!`))} ${error}
${_DbPush.help}`);
    }
    return _DbPush.help;
  }
};
